#Experiment configuration file.

#PT Lightning trainer arguments.
#Documentation: https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html
#Comment out options you aren't using
train:
  accelerator: "gpu" #str, e.g. "gpu"
  devices: 2 #int
  # num_nodes: #int
  strategy: "ddp_sharded" #str
  # precision: #str
  # auto_scale_batch_size: #bool
  # auto_select_gpus: #bool
  enable_checkpointing: True #bool
  check_val_every_n_epoch: 1 #int
  default_root_dir: "./lightning_logs" #str
  logger: True #bool
  # log_every_n_steps: #int
  enable_progress_bar: True #bool
  # profiler: #str
  max_epochs: 15000 #int
  # max_steps: #int

#Model arguments
model:
  type: "QCAE" #str <CAE|QCAE|QCNN>
  module: "skip" #str <skip|pool>, CAE and QCAE only
  spatial_dim: 2 #int
  latent_dim: 10 #int
  point_seq: [9074, 2500, 625, 100] #list[int], QC only
  stages: 3 #int
  loss_fn: "MSELoss" #str, SobolevLoss or loss from torch.nn
  optimizer: "Adam" #str, optimizer from torch.optim
  learning_rate: 0.01 #float

  conv_params:
    in_points: [9074, 2500, 625] #list[int]
    out_points: [2500, 625, 100] #list[int]
    in_channels: [4, 12, 20] #list[int]
    out_channels: [8, 16, 24] #list[int]
    bias: [True] #list[bool]
    filter_seq: [[4, 4]] #[list[int]], QC only
    filter_mode: ["single"] #string <single|share_in|nested>, QC only


#PT LightningDataModule arguments
data:
  module: "mesh_data" #str <grid_data|mesh_data>
  data_dir: "data/ignition_mesh" #str
  spatial_dim: 2 #int
  num_points: 9074 #int, mesh only
  batch_size: 8 #int
  channels: [] #list[int], AE only
  shuffle: True #bool

#Miscellaneous arguments
misc:
  make_gif: True #bool
  compute_stats: True #bool
  early_stopping: False #bool
